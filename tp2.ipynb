{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1: Data Preparation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1: Loading the Turtle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'entités uniques : 65\n",
      "Nombre de relations uniques : 15\n",
      "Nombre de triples dans le graphe : 95\n",
      "\n",
      "Exemples d'entités et leurs relations :\n",
      "Entité: http://www.inria.fr/human/data#John\n",
      "  Relation: http://www.inria.fr/human#hasParent\n",
      "  Relation: http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "Entité: http://www.inria.fr/human/data#Eve\n",
      "  Relation: http://www.inria.fr/human#hasSpouse\n",
      "  Relation: http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "  Relation: http://www.inria.fr/human#hasFriend\n",
      "Entité: http://www.inria.fr/human/data#Jennifer\n",
      "  Relation: http://www.inria.fr/human#hasSpouse\n",
      "  Relation: http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "Entité: http://www.inria.fr/human/data#Karl\n",
      "  Relation: http://www.inria.fr/human#hasSpouse\n",
      "  Relation: http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "  Relation: http://www.inria.fr/human#hasFriend\n",
      "Entité: http://www.inria.fr/human/data#Gaston\n",
      "  Relation: http://www.inria.fr/human#hasChild\n",
      "  Relation: http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from collections import defaultdict\n",
    "\n",
    "# Charger le fichier Turtle\n",
    "human_file = \"data/human.ttl\"\n",
    "graph = Graph()\n",
    "graph.parse(human_file, format=\"turtle\")\n",
    "\n",
    "# Question 1: How many unique entities and relations are in human.ttl?\n",
    "entities = set()\n",
    "relations = set()\n",
    "\n",
    "for sujet, predicat, objet in graph:\n",
    "    entities.add(sujet)\n",
    "    entities.add(objet)\n",
    "    relations.add(predicat)\n",
    "\n",
    "print(f\"Nombre d'entités uniques : {len(entities)}\")\n",
    "print(f\"Nombre de relations uniques : {len(relations)}\")\n",
    "\n",
    "# Question 2: What is the size of the graph in terms of the number of triples?\n",
    "num_triples = len(graph)\n",
    "print(f\"Nombre de triples dans le graphe : {num_triples}\")\n",
    "\n",
    "# Question 3: Identify some entities and relationships that could illustrate interesting link cases\n",
    "entity_relations = defaultdict(set)\n",
    "for sujet, predicat, objet in graph:\n",
    "    if isinstance(sujet, URIRef) and isinstance(objet, URIRef):\n",
    "        entity_relations[sujet].add(predicat)\n",
    "\n",
    "print(\"\\nExemples d'entités et leurs relations :\")\n",
    "for entity, rels in list(entity_relations.items())[:5]:  # Affiche les 5 premières entités pour l'exemple\n",
    "    print(f\"Entité: {entity}\")\n",
    "    for rel in rels:\n",
    "        print(f\"  Relation: {rel}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2: Preparing Data for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Preparation Summary:\n",
      "Total triples: 95\n",
      "Training triples: 76\n",
      "Test triples: 19\n",
      "Negative samples generated: 76\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "triples = list(graph)\n",
    "\n",
    "# Split triples into training and test sets\n",
    "train_triples, test_triples = train_test_split(\n",
    "    triples, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Generate negative samples\n",
    "def generate_negative_samples(positive_triples, num_neg_samples=1):\n",
    "    # Extract unique entities from the graph\n",
    "    entities = set()\n",
    "    for sujet, predicat, objet in graph:\n",
    "        if isinstance(sujet, URIRef) and isinstance(objet, URIRef):\n",
    "            entities.add(sujet)\n",
    "            entities.add(objet)\n",
    "    \n",
    "    negative_samples = []\n",
    "    entities_list = list(entities)\n",
    "    \n",
    "    for s, p, o in positive_triples:\n",
    "        for _ in range(num_neg_samples):\n",
    "            # Randomly decide to corrupt subject or object\n",
    "            corrupt_subject = np.random.random() < 0.5\n",
    "            \n",
    "            if corrupt_subject:\n",
    "                # Replace subject with a random entity\n",
    "                neg_s = np.random.choice(entities_list)\n",
    "                neg_sample = (neg_s, p, o)\n",
    "            else:\n",
    "                # Replace object with a random entity\n",
    "                neg_o = np.random.choice(entities_list)\n",
    "                neg_sample = (s, p, neg_o)\n",
    "            \n",
    "            # Ensure negative sample is not in original graph\n",
    "            while neg_sample in graph:\n",
    "                if corrupt_subject:\n",
    "                    neg_s = np.random.choice(entities_list)\n",
    "                    neg_sample = (neg_s, p, o)\n",
    "                else:\n",
    "                    neg_o = np.random.choice(entities_list)\n",
    "                    neg_sample = (s, p, neg_o)\n",
    "            \n",
    "            negative_samples.append(neg_sample)\n",
    "    \n",
    "    return negative_samples\n",
    "\n",
    "# Generate negative samples for training set\n",
    "train_negative_samples = generate_negative_samples(train_triples)\n",
    "\n",
    "# Print some information about the data preparation\n",
    "print(\"\\nData Preparation Summary:\")\n",
    "print(f\"Total triples: {len(triples)}\")\n",
    "print(f\"Training triples: {len(train_triples)}\")\n",
    "print(f\"Test triples: {len(test_triples)}\")\n",
    "print(f\"Negative samples generated: {len(train_negative_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2: Implementation of Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.triples.triples_factory:You're trying to map triples with 27 entities and 2 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "WARNING:pykeen.triples.triples_factory:In total 29 from 49 triples were filtered out\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 593866165.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.60epoch/s, loss=0.0456, prev_loss=0.0864]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 462825105.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for TransE with embedding_dim=200:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  40.943986\n",
      "1    tail   optimistic  standard_deviation  42.768534\n",
      "2    both   optimistic  standard_deviation  45.424876\n",
      "3    head    realistic  standard_deviation  40.943985\n",
      "4    tail    realistic  standard_deviation  42.768532\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k   0.089906\n",
      "221  both    realistic  adjusted_hits_at_k   0.008391\n",
      "222  head  pessimistic  adjusted_hits_at_k  -0.073323\n",
      "223  tail  pessimistic  adjusted_hits_at_k   0.089906\n",
      "224  both  pessimistic  adjusted_hits_at_k   0.008391\n",
      "\n",
      "[225 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.64epoch/s, loss=0.985, prev_loss=0.985]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1694864254.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for DistMult with embedding_dim=200:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  39.355146\n",
      "1    tail   optimistic  standard_deviation  43.637598\n",
      "2    both   optimistic  standard_deviation  41.564220\n",
      "3    head    realistic  standard_deviation  39.355145\n",
      "4    tail    realistic  standard_deviation  43.637600\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k  -0.017164\n",
      "221  both    realistic  adjusted_hits_at_k  -0.018409\n",
      "222  head  pessimistic  adjusted_hits_at_k  -0.019657\n",
      "223  tail  pessimistic  adjusted_hits_at_k  -0.017164\n",
      "224  both  pessimistic  adjusted_hits_at_k  -0.018409\n",
      "\n",
      "[225 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.19epoch/s, loss=9.08, prev_loss=7.93]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 698384999.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ComplEx with embedding_dim=200:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  42.345572\n",
      "1    tail   optimistic  standard_deviation  43.568194\n",
      "2    both   optimistic  standard_deviation  43.012527\n",
      "3    head    realistic  standard_deviation  42.345570\n",
      "4    tail    realistic  standard_deviation  43.568195\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k   0.089906\n",
      "221  both    realistic  adjusted_hits_at_k   0.115592\n",
      "222  head  pessimistic  adjusted_hits_at_k   0.141342\n",
      "223  tail  pessimistic  adjusted_hits_at_k   0.089906\n",
      "224  both  pessimistic  adjusted_hits_at_k   0.115592\n",
      "\n",
      "[225 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.49epoch/s, loss=0.462, prev_loss=0.448]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 323179714.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for RotatE with embedding_dim=200:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  10.256705\n",
      "1    tail   optimistic  standard_deviation  21.230815\n",
      "2    both   optimistic  standard_deviation  16.795070\n",
      "3    head    realistic  standard_deviation  10.256705\n",
      "4    tail    realistic  standard_deviation  21.230814\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k   0.518186\n",
      "221  both    realistic  adjusted_hits_at_k   0.329994\n",
      "222  head  pessimistic  adjusted_hits_at_k   0.141342\n",
      "223  tail  pessimistic  adjusted_hits_at_k   0.518186\n",
      "224  both  pessimistic  adjusted_hits_at_k   0.329994\n",
      "\n",
      "[225 rows x 4 columns]\n",
      "\n",
      "Available metrics for TransE: ['standard_deviation' 'harmonic_mean_rank' 'z_arithmetic_mean_rank'\n",
      " 'inverse_median_rank' 'variance' 'inverse_harmonic_mean_rank'\n",
      " 'inverse_arithmetic_mean_rank' 'median_absolute_deviation'\n",
      " 'z_inverse_harmonic_mean_rank' 'adjusted_geometric_mean_rank_index'\n",
      " 'median_rank' 'z_geometric_mean_rank'\n",
      " 'adjusted_arithmetic_mean_rank_index' 'count' 'arithmetic_mean_rank'\n",
      " 'adjusted_inverse_harmonic_mean_rank' 'inverse_geometric_mean_rank'\n",
      " 'geometric_mean_rank' 'adjusted_arithmetic_mean_rank' 'hits_at_1'\n",
      " 'hits_at_3' 'hits_at_5' 'hits_at_10' 'z_hits_at_k' 'adjusted_hits_at_k']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.92epoch/s, loss=0.108, prev_loss=0.186]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1367371125.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for TransE with embedding_dim=100:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  40.270678\n",
      "1    tail   optimistic  standard_deviation  40.962910\n",
      "2    both   optimistic  standard_deviation  41.663766\n",
      "3    head    realistic  standard_deviation  40.270679\n",
      "4    tail    realistic  standard_deviation  40.962910\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k   0.036371\n",
      "221  both    realistic  adjusted_hits_at_k   0.008391\n",
      "222  head  pessimistic  adjusted_hits_at_k  -0.019657\n",
      "223  tail  pessimistic  adjusted_hits_at_k   0.036371\n",
      "224  both  pessimistic  adjusted_hits_at_k   0.008391\n",
      "\n",
      "[225 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.76epoch/s, loss=0.0227, prev_loss=0.105]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 110447987.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for TransE with embedding_dim=200:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  40.776096\n",
      "1    tail   optimistic  standard_deviation  50.628154\n",
      "2    both   optimistic  standard_deviation  48.541838\n",
      "3    head    realistic  standard_deviation  40.776096\n",
      "4    tail    realistic  standard_deviation  50.628155\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k   0.089906\n",
      "221  both    realistic  adjusted_hits_at_k   0.035192\n",
      "222  head  pessimistic  adjusted_hits_at_k  -0.019657\n",
      "223  tail  pessimistic  adjusted_hits_at_k   0.089906\n",
      "224  both  pessimistic  adjusted_hits_at_k   0.035192\n",
      "\n",
      "[225 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu: 100%|██████████| 50/50 [00:05<00:00,  9.60epoch/s, loss=0.0544, prev_loss=0.0966]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for TransE with embedding_dim=300:\n",
      "     Side    Rank_type              Metric      Value\n",
      "0    head   optimistic  standard_deviation  42.433801\n",
      "1    tail   optimistic  standard_deviation  35.504084\n",
      "2    both   optimistic  standard_deviation  44.390701\n",
      "3    head    realistic  standard_deviation  42.433804\n",
      "4    tail    realistic  standard_deviation  35.504082\n",
      "..    ...          ...                 ...        ...\n",
      "220  tail    realistic  adjusted_hits_at_k   0.250511\n",
      "221  both    realistic  adjusted_hits_at_k   0.088792\n",
      "222  head  pessimistic  adjusted_hits_at_k  -0.073323\n",
      "223  tail  pessimistic  adjusted_hits_at_k   0.250511\n",
      "224  both  pessimistic  adjusted_hits_at_k   0.088792\n",
      "\n",
      "[225 rows x 4 columns]\n",
      "\n",
      "Best TransE hits_at_10: 0.05 with embedding_dim=100\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.models import TransE, DistMult, ComplEx, RotatE\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# Load the Turtle files\n",
    "graph = Graph()\n",
    "graph.parse(\"data/human.ttl\", format=\"turtle\")\n",
    "graph.parse(\"data/humanrdfs.ttl\", format=\"turtle\")\n",
    "\n",
    "# Extract triples\n",
    "triples = [(str(s), str(p), str(o)) for s, p, o in graph]\n",
    "\n",
    "# Convert triples to a NumPy array\n",
    "triples_array = np.array(triples, dtype=object)\n",
    "\n",
    "# Split triples into training and test sets\n",
    "train_triples, test_triples = train_test_split(\n",
    "    triples_array, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create TriplesFactory for training and testing\n",
    "training = TriplesFactory.from_labeled_triples(train_triples)\n",
    "testing = TriplesFactory.from_labeled_triples(test_triples, entity_to_id=training.entity_to_id, relation_to_id=training.relation_to_id)\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate_model(model_class, training, testing, embedding_dim=200):\n",
    "    result = pipeline(\n",
    "        model=model_class,\n",
    "        training=training,\n",
    "        testing=testing,\n",
    "        model_kwargs=dict(embedding_dim=embedding_dim),\n",
    "        training_kwargs=dict(num_epochs=50),\n",
    "        evaluation_kwargs=dict(use_tqdm=False),\n",
    "    )\n",
    "    print(f\"\\nResults for {model_class.__name__} with embedding_dim={embedding_dim}:\")\n",
    "    metric_results_df = result.metric_results.to_df()\n",
    "    print(metric_results_df)\n",
    "    return metric_results_df\n",
    "\n",
    "# Train and evaluate TransE\n",
    "transE_results = train_and_evaluate_model(TransE, training, testing)\n",
    "\n",
    "# Train and evaluate DistMult\n",
    "distMult_results = train_and_evaluate_model(DistMult, training, testing)\n",
    "\n",
    "# Train and evaluate ComplEx\n",
    "complEx_results = train_and_evaluate_model(ComplEx, training, testing)\n",
    "\n",
    "# Train and evaluate RotatE\n",
    "rotatE_results = train_and_evaluate_model(RotatE, training, testing)\n",
    "\n",
    "# Inspect available metrics for TransE\n",
    "available_metrics = transE_results['Metric'].unique()\n",
    "print(\"\\nAvailable metrics for TransE:\", available_metrics)\n",
    "\n",
    "# Choose a valid metric for tuning (e.g., 'hits_at_10')\n",
    "target_metric = 'hits_at_10'  # Specify the target metric\n",
    "\n",
    "# Tune embedding dimensions for TransE as an example\n",
    "best_score = 0\n",
    "best_embedding_dim = 0\n",
    "\n",
    "for embedding_dim in [100, 200, 300]:\n",
    "    result = pipeline(\n",
    "        model=TransE,\n",
    "        training=training,\n",
    "        testing=testing,\n",
    "        model_kwargs=dict(embedding_dim=embedding_dim),\n",
    "        training_kwargs=dict(num_epochs=50),\n",
    "        evaluation_kwargs=dict(use_tqdm=False),\n",
    "    )\n",
    "    result_df = result.metric_results.to_df()\n",
    "    print(f\"\\nResults for TransE with embedding_dim={embedding_dim}:\")\n",
    "    print(result_df)\n",
    "    if target_metric in result_df['Metric'].values:\n",
    "        mrr_score = result_df[result_df['Metric'] == target_metric]['Value'].values[0]  # Access the metric score correctly\n",
    "        if mrr_score > best_score:\n",
    "            best_score = mrr_score\n",
    "            best_embedding_dim = embedding_dim\n",
    "    else:\n",
    "        print(f\"{target_metric} not found in results for embedding_dim={embedding_dim}\")\n",
    "\n",
    "print(f\"\\nBest TransE {target_metric}: {best_score} with embedding_dim={best_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TransE vs. ComplEx :\n",
    "\n",
    "TransE :\n",
    "\n",
    "Représentations des Entités : TransE représente les entités et les relations comme des vecteurs dans un espace vectoriel continu.\\\n",
    "Il utilise une opération de traduction simple pour prédire les liens manquants : ( h + r ≈ t ).  \n",
    "Performance : D'après les résultats, TransE a un rang moyen arithmétique relativement élevé et des scores plus faibles en hits@10 comparés à ComplEx.\\\n",
    "Cela suggère que TransE a du mal à capturer des relations complexes entre les entités.  \n",
    "\\\n",
    "ComplEx :\n",
    "\n",
    "Représentations des Entités : ComplEx étend TransE en utilisant des embeddings à valeurs complexes.\\\n",
    "Il représente les entités et les relations comme des vecteurs complexes, ce qui lui permet de capturer des interactions et des relations plus complexes.  \n",
    "Performance : ComplEx a des rangs moyens arithmétiques significativement plus bas et des scores hits@10 plus élevés comparés à TransE.\\\n",
    "Cela indique que ComplEx est plus performant pour capturer des relations complexes et fournir des prédictions plus précises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a mapping from entity to category based on their relationships\n",
    "entity_to_category = defaultdict(list)\n",
    "for subj, pred, obj in graph:\n",
    "    entity_to_category[str(subj)].append(str(pred))\n",
    "    entity_to_category[str(obj)].append(str(pred))\n",
    "\n",
    "# For simplicity, assign the most common relation as the category\n",
    "entity_category = {entity: max(set(rels), key=rels.count) for entity, rels in entity_to_category.items()}\n",
    "\n",
    "# Extract entity embeddings\n",
    "entity_embeddings = result.model.entity_representations[0]().cpu().detach().numpy()\n",
    "entity_ids = list(result.training.entity_to_id.keys())\n",
    "\n",
    "# Reduce dimensions to 2D using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(entity_embeddings)\n",
    "\n",
    "# Prepare colors for each category\n",
    "categories = list(set(entity_category.values()))\n",
    "palette = sns.color_palette('hsv', len(categories))\n",
    "color_map = {category: palette[i] for i, category in enumerate(categories)}\n",
    "\n",
    "# Assign colors to entities based on their category\n",
    "colors = [color_map.get(entity_category.get(entity_id, 'Other'), (0, 0, 0)) for entity_id in entity_ids]\n",
    "\n",
    "# Plot the embeddings with colors\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, alpha=0.6)\n",
    "\n",
    "# Optional: Add legend (may be crowded if many categories)\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=category,\n",
    "                          markerfacecolor=color_map[category], markersize=10)\n",
    "                   for category in categories]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.title('Entity Embeddings Visualized with t-SNE')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(entity_embeddings)\n",
    "\n",
    "# Plot the embeddings with colors\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors, alpha=0.6)\n",
    "\n",
    "# Optional: Add legend (may be crowded if many categories)\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=category,\n",
    "                          markerfacecolor=color_map[category], markersize=10)\n",
    "                   for category in categories]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.title('Entity Embeddings Visualized with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are entities with similar relationships clustered in embedding space?\n",
    "    - Non, les entités avec des relations similaires ne sont pas nécessairement regroupées dans l'espace d'embedding. Que ce soit avec l'analyse PCA ou t-SNE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Determine the number of clusters (you might set it equal to the number of categories)\n",
    "num_clusters = len(categories)\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(embeddings_2d)\n",
    "\n",
    "# Plot the clustered embeddings\n",
    "plt.figure(figsize=(12, 12))\n",
    "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=cluster_labels, cmap='tab10', alpha=0.6)\n",
    "\n",
    "# Add legend for clusters\n",
    "plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "plt.title('Entity Embeddings Clusters Visualized with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "\n",
    "# Encode actual categories\n",
    "label_encoder = LabelEncoder()\n",
    "true_labels = label_encoder.fit_transform([entity_category.get(entity_id, 'Other') for entity_id in entity_ids])\n",
    "\n",
    "# Evaluate clustering performance\n",
    "homogeneity = homogeneity_score(true_labels, cluster_labels)\n",
    "completeness = completeness_score(true_labels, cluster_labels)\n",
    "v_measure = v_measure_score(true_labels, cluster_labels)\n",
    "\n",
    "print(f\"Homogeneity Score: {homogeneity:.2f}\")\n",
    "print(f\"Completeness Score: {completeness:.2f}\")\n",
    "print(f\"V-Measure Score: {v_measure:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Identify and analyze clusters of entities. Do these clusters correspond to coherent entity\n",
    "types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE 3: Model Evaluation and Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_evaluation_metrics():\n",
    "    \"\"\"\n",
    "    Detailed explanation of link prediction evaluation metrics\n",
    "    \"\"\"\n",
    "    metrics_explanation = {\n",
    "        \"Mean Rank\": {\n",
    "            \"Définition\": \"Rang moyen de l'entité correcte parmi toutes les entités possibles lors de la prédiction d'un lien manquant.\",\n",
    "            \"Interprétation\": \"Des valeurs plus faibles indiquent une meilleure performance du modèle. Un rang de 1 signifie que le modèle prédit parfaitement l'entité correcte.\",\n",
    "            \"Calcul\": \"Pour chaque triple test, classez les entités candidates et calculez la moyenne de ces classements pour tous les triples tests.\"\n",
    "        },\n",
    "        \"Mean Reciprocal Rank (MRR)\": {\n",
    "            \"Définition\": \"Moyenne des rangs réciproques des entités correctes.\",\n",
    "            \"Interprétation\": \"Des valeurs élevées indiquent une meilleure performance. Les valeurs sont comprises entre 0 et 1, la valeur 1 correspondant à une prédiction parfaite.\",\n",
    "            \"Calcul\": \"1 / rang pour chaque triple test, puis moyenne sur l'ensemble des triples tests.\"\n",
    "        },\n",
    "        \"Hits@K\": {\n",
    "            \"Définition\": \"Proportion de triplets de test où l'entité correcte est classée dans les K premières positions.\",\n",
    "            \"Interprétation\": \"Des valeurs élevées indiquent une meilleure performance. Mesuré pour différentes valeurs de K (1, 3, 10).\",\n",
    "            \"Calcul\": \"Pourcentage de triplets de test où l'entité correcte se trouve parmi les K premières entités prédites.\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics_explanation\n",
    "\n",
    "def comprehensive_model_evaluation(models_results):\n",
    "    results_summary = []\n",
    "    \n",
    "    for name, result in models_results.items():\n",
    "        metrics_df = result\n",
    "        \n",
    "        # Initialize default values\n",
    "        model_metrics = {\n",
    "            'model_name': name,\n",
    "            'Mean Rank': None,\n",
    "            'MRR': None,\n",
    "            'Hits@1': None,\n",
    "            'Hits@3': None,\n",
    "            'Hits@10': None\n",
    "        }\n",
    "        \n",
    "        # Safely get metrics with error handling\n",
    "        def get_metric_value(metric_name):\n",
    "            filtered = metrics_df[metrics_df['Metric'] == metric_name]['Value']\n",
    "            return filtered.values[0] if not filtered.empty else None\n",
    "        \n",
    "        # Update metrics if they exist\n",
    "        metric_mappings = {\n",
    "            'arithmetic_mean_rank': 'Mean Rank',\n",
    "            'mean_reciprocal_rank': 'MRR',\n",
    "            'hits_at_1': 'Hits@1',\n",
    "            'hits_at_3': 'Hits@3',\n",
    "            'hits_at_10': 'Hits@10'\n",
    "        }\n",
    "        \n",
    "        for metric_key, metric_name in metric_mappings.items():\n",
    "            value = get_metric_value(metric_key)\n",
    "            if value is not None:\n",
    "                model_metrics[metric_name] = value\n",
    "        \n",
    "        results_summary.append(model_metrics)\n",
    "    \n",
    "    # Convert to DataFrame for easy comparison\n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    \n",
    "    # Sort by different metrics to identify top performers\n",
    "    print(\"Top Models by Different Metrics:\")\n",
    "    print(\"\\nSorted by Mean Rank (Lower is Better):\")\n",
    "    print(results_df.sort_values('Mean Rank'))\n",
    "    \n",
    "    print(\"\\nSorted by MRR (Higher is Better):\")\n",
    "    print(results_df.sort_values('MRR', ascending=False))\n",
    "    \n",
    "    print(\"\\nSorted by Hits@10 (Higher is Better):\")\n",
    "    print(results_df.sort_values('Hits@10', ascending=False))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "metrics_explanation = explain_evaluation_metrics()\n",
    "for metric, details in metrics_explanation.items():\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Evaluate the models using comprehensive_model_evaluation with the train dataset\n",
    "\n",
    "transE_results = train_and_evaluate_model(TransE, training, training)\n",
    "distMult_results = train_and_evaluate_model(DistMult, training, training)\n",
    "complEx_results = train_and_evaluate_model(ComplEx, training, training)\n",
    "rotatE_results = train_and_evaluate_model(RotatE, training, training)\n",
    "\n",
    "models_results = {\n",
    "    \"TransE\": transE_results,\n",
    "    \"DistMult\": distMult_results,\n",
    "    \"ComplEx\": complEx_results,\n",
    "    \"RotatE\": rotatE_results\n",
    "}\n",
    "\n",
    "train_evaluation = comprehensive_model_evaluation(models_results)\n",
    "\n",
    "# Evaluate the models using comprehensive_model_evaluation with the test dataset\n",
    "\n",
    "transE_results = train_and_evaluate_model(TransE, training, testing)\n",
    "distMult_results = train_and_evaluate_model(DistMult, training, testing)\n",
    "complEx_results = train_and_evaluate_model(ComplEx, training, testing)\n",
    "rotatE_results = train_and_evaluate_model(RotatE, training, testing)\n",
    "\n",
    "models_results = {\n",
    "    \"TransE\": transE_results,\n",
    "    \"DistMult\": distMult_results,\n",
    "    \"ComplEx\": complEx_results,\n",
    "    \"RotatE\": rotatE_results\n",
    "}\n",
    "\n",
    "test_evaluation = comprehensive_model_evaluation(models_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define each metric and explain how they assess link prediction quality.\n",
    "\n",
    "    <b>Mean Rank</b>:  \n",
    "        Rang moyen de l'entité correcte parmi toutes les entités possibles lors de la prédiction d'un lien manquant.  \n",
    "        Interprétation: Des valeurs plus faibles indiquent une meilleure performance du modèle. Un rang de 1 signifie que le modèle prédit parfaitement l'entité correcte.  \n",
    "        Calcul: Pour chaque triple test, classez les entités candidates et calculez la moyenne de ces classements pour tous les triples tests.\n",
    "    \n",
    "    <b>Mean Reciprocal Rank (MRR)</b>:  \n",
    "        Moyenne des rangs réciproques des entités correctes.  \n",
    "        Interprétation: Des valeurs élevées indiquent une meilleure performance. Les valeurs sont comprises entre 0 et 1, la valeur 1 correspondant à une prédiction parfaite.  \n",
    "        Calcul: 1 / rang pour chaque triple test, puis moyenne sur l'ensemble des triples tests.\n",
    "    \n",
    "    <b>Hits@K</b>:  \n",
    "        Proportion de triplets de test où l'entité correcte est classée dans les K premières positions.  \n",
    "        Interprétation: Des valeurs élevées indiquent une meilleure performance. Mesuré pour différentes valeurs de K (1, 3, 10).   \n",
    "        Calcul: Pourcentage de triplets de test où l'entité correcte se trouve parmi les K premières entités prédites.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Interpret the results for each model and identify the top-performing models for this dataset\n",
    "((a) with the train dataset, (b) with the test dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics Comparison:\n",
      "\n",
      "Train Dataset:\n",
      "  model_name  Mean Rank   MRR    Hits@1    Hits@3   Hits@10\n",
      "0     TransE   2.855670  None  0.000000  0.845361  0.979381\n",
      "1   DistMult   1.061856  None  0.963918  0.994845  1.000000\n",
      "2    ComplEx  52.541237  None  0.010309  0.030928  0.092784\n",
      "3     RotatE   1.603093  None  0.798969  0.917526  0.989691\n",
      "\n",
      "Test Dataset:\n",
      "  model_name  Mean Rank   MRR  Hits@1  Hits@3  Hits@10\n",
      "0     TransE      60.00  None     0.0    0.00      0.1\n",
      "1   DistMult      73.60  None     0.0    0.05      0.1\n",
      "2    ComplEx      85.15  None     0.0    0.00      0.0\n",
      "3     RotatE      19.80  None     0.1    0.10      0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluation Metrics Comparison:\")\n",
    "print(\"\\nTrain Dataset:\")\n",
    "print(train_evaluation)\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DistMult obtient des résultats exceptionnels sur l'ensemble d'apprentissage pour toutes les mesures, mais ne se généralise pas bien à l'ensemble de test.\n",
    "- RotatE présente un bon équilibre entre les performances d'entraînement et de test, avec les meilleurs résultats de test pour toutes les mesures.\n",
    "- TransE présente des performances raisonnables sur l'ensemble d'apprentissage, mais une baisse significative des performances sur l'ensemble de test.\n",
    "- ComplEx obtient des résultats médiocres à la fois sur l'ensemble d'entraînement et sur l'ensemble de test.\n",
    "  \n",
    "Dans l'ensemble, RotatE semble être le meilleur modèle en termes de généralisation à l'ensemble de test, tandis que DistMult est le meilleur sur l'ensemble d'apprentissage, mais overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2: Comparative Analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
